{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdRwkJBn70nX"
   },
   "source": [
    "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2htC-oV70ne"
   },
   "source": [
    "The purpose of this exercise is to understand text representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARqm7u6B70ne"
   },
   "source": [
    "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification or text mining task: Classifying text as either Positive or Negative sentiment.\n",
    "Features: 1) Word Count: Word count of the text can be used to identify the sentiment of the text. A\n",
    "higher word count will generally indicate a more positive sentiment, while a lower word count may\n",
    "indicate a more negative sentiment. 2) Sentiment Lexicon: Identifying words in the text that are\n",
    "associated with either positive or negative sentiment, such as happy, sad, good, bad, etc. 3)\n",
    "Content Analysis: Analyzing the context of the text, such as the overall topic, writing style and use\n",
    "of language, to identify the sentiment of the text.\n",
    "4) Emotion Detection: Identifying emotions such as joy, anger, surprise, and so on, from the text by\n",
    "analyzing the facial expressions and body language used in the text. 5) Readability Analysis:\n",
    "Analyzing the readability of the text to determine the complexity of the language used, which can\n",
    "be used to identify the sentiment of the text. 6) Grammar Analysis: Identifying patterns of\n",
    "grammar and syntax in the text in order to identify the sentiment of the text. These features could\n",
    "be helpful in building a machine learning model because they each have the potential to\n",
    "accurately identify the sentiment of the text. Word count and sentiment lexicon capture the explicit\n",
    "sentiment of the text, while content analysis and emotion detection\n",
    "Explanation:\n",
    "Word count and sentiment lexicon are helpful in identifying the explicit sentiment expressed in the\n",
    "text, as they look for words that are associated with either positive or negative sentiment. Content\n",
    "analysis and emotion detection can be used to identify the implicit sentiment of the text by\n",
    "analyzing the context of the text and looking for facial expressions and body language that may\n",
    "indicate a certain sentiment. Readability analysis can be used to identify how complex or easy the\n",
    "text is, which can provide insight into the sentiment expressed by the author. And finally, grammar\n",
    "analysis can help to identify patterns of grammar and syntax that may indicate a certain\n",
    "sentiment.\n",
    "capture the implicit sentiment of the text. Readability analysis can help to identify how complex or\n",
    "easy the text is, which can be used to decipher the sentiment of the text. And finally, grammar\n",
    "analysis can provide insight into the sentiment by analyzing the grammar and syntax used in the\n",
    "text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEUjBE6C70nf"
   },
   "source": [
    "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EoQX5s4O70nf"
   },
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text1 = 'This is a great day for learning Python programming language!'\n",
    "text2 = 'I am excited to use the new Python libraries!'\n",
    "\n",
    "# Feature extraction\n",
    "# 1. Word count\n",
    "word_count1 = len(text1.split())\n",
    "word_count2 = len(text2.split())\n",
    "\n",
    "# 2. Sentence length\n",
    "sentence_length1 = len(text1)\n",
    "sentence_length2 = len(text2)\n",
    "\n",
    "# 3. Number of special characters\n",
    "special_characters1 = len([c for c in text1 if c.isalpha() == False and c != \" \"])\n",
    "special_characters2 = len([c for c in text2 if c.isalpha() == False and c != \" \"])\n",
    "\n",
    "# 4. Number of capital words\n",
    "capital_words1 = len([w for w in text1.split() if w[0].isupper()])\n",
    "capital_words2 = len([w for w in text2.split() if w[0].isupper()])\n",
    "\n",
    "# 5. Average length of words in sentence\n",
    "sum_characters1 = sum([len(w) for w in text1.split()])\n",
    "average_length1 = sum_characters1 / word_count1\n",
    "\n",
    "sum_characters2 = sum([len(w) for w in text2.split()])\n",
    "average_length2 = sum_characters2 / word_count2\n",
    "\n",
    "# 6. Ratio of unique words to total words\n",
    "unique_words1 = len(set(text1.split()))\n",
    "ratio_unique_words1 = unique_words1 / word_count1\n",
    "\n",
    "unique_words2 = len(set(text2.split()))\n",
    "ratio_unique_words2 = unique_words2 / word_count2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oSK4soH70nf"
   },
   "source": [
    "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
    "\n",
    "Select the most important features you extracted above, rank the features based on their importance in the descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2CRuXfV570ng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking of Features Based on Their Importance:\n",
      "1. Information Gain and Conditional Mutual Information\n",
      "2. Term Frequency-Inverse Document Frequency\n",
      "3. Chi-Square Test\n",
      "4. Correlation-based Feature Selection\n",
      "5. Genetic Algorithm\n",
      "6. Wrapper Method\n",
      "\n",
      "Explanation:\n",
      "Information Gain and Conditional Mutual Information: This is a measure of the relevance of a set of features to the target attribute. It identifies the most important features by considering both the relevance and dependence between features.\n",
      "Term Frequency-Inverse Document Frequency: This measure considers the frequency of a feature in a given sample and assigns more importance to those features that are more distinct and rare among all samples.\n",
      "Chi-Square Test: This is an independence measure that quantifies the strength of association between a set of features and the target attribute.\n",
      "Correlation-based Feature Selection: This method measures the correlation between features and the target attribute and selects those that are most strongly correlated.\n",
      "Genetic Algorithm: This method applies evolutionary algorithms to the feature selection problem by using a fitness value to evaluate the importance of each feature.\n",
      "Wrapper Method: This method evaluates the performance of a subset of features on some learning algorithm and selects those that yield the best performance.\n"
     ]
    }
   ],
   "source": [
    " # Define a list of feature selection methods and their explanations\n",
    "feature_methods = [\n",
    "    {\n",
    "        'name': 'Information Gain and Conditional Mutual Information',\n",
    "        'explanation': 'This is a measure of the relevance of a set of features to the target attribute. It identifies the most important features by considering both the relevance and dependence between features.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'Term Frequency-Inverse Document Frequency',\n",
    "        'explanation': 'This measure considers the frequency of a feature in a given sample and assigns more importance to those features that are more distinct and rare among all samples.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'Chi-Square Test',\n",
    "        'explanation': 'This is an independence measure that quantifies the strength of association between a set of features and the target attribute.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'Correlation-based Feature Selection',\n",
    "        'explanation': 'This method measures the correlation between features and the target attribute and selects those that are most strongly correlated.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'Genetic Algorithm',\n",
    "        'explanation': 'This method applies evolutionary algorithms to the feature selection problem by using a fitness value to evaluate the importance of each feature.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wrapper Method',\n",
    "        'explanation': 'This method evaluates the performance of a subset of features on some learning algorithm and selects those that yield the best performance.',\n",
    "    },\n",
    "]\n",
    "\n",
    "# Print the ranking of features based on their importance\n",
    "print(\"Ranking of Features Based on Their Importance:\")\n",
    "for i, method in enumerate(feature_methods, start=1):\n",
    "    print(f\"{i}. {method['name']}\")\n",
    "\n",
    "# Print explanations\n",
    "print(\"\\nExplanation:\")\n",
    "for method in feature_methods:\n",
    "    print(f\"{method['name']}: {method['explanation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nZGAOwl70ng"
   },
   "source": [
    "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\felloh\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bert-embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b4HoWK-i70ng"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing packages\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbert_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertEmbedding\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Instantiating the BertEmbedding model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bert_embedding'"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "from bert_embedding import BertEmbedding\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Instantiating the BertEmbedding model\n",
    "bert_embedding = BertEmbedding()\n",
    "\n",
    "# Defining the text data\n",
    "text_data = [\n",
    "    'The quick brown fox jumps over the lazy dog',\n",
    "    'A black fox jumps quickly over a sleeping dog'\n",
    "]\n",
    "\n",
    "# Defining the query\n",
    "query = 'A brown fox jumping over a sleeping dog'\n",
    "\n",
    "# Defining an empty list to store the embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Calculating the embeddings for each piece of text\n",
    "for text in text_data:\n",
    "    result = bert_embedding([text])\n",
    "    embedding = result[0][1]\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Calculating the embeddings for the query\n",
    "query_embedding_result = bert_embedding([query])\n",
    "query_embedding = query_embedding_result[0][1]\n",
    "\n",
    "# Calculating the cosine similarity between the query and each text\n",
    "scores = []\n",
    "for embedding in embeddings:\n",
    "    score = cosine_similarity([embedding], [query_embedding])\n",
    "    scores.append(score[0][0])\n",
    "\n",
    "# Creating a dictionary\n",
    "results = dict(zip(text_data, scores))\n",
    "\n",
    "# Ranking the text data by similarity in descending order\n",
    "ranked_results = sorted(results.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Ranking of Text Data by Similarity:\")\n",
    "for result in ranked_results:\n",
    "    print(result[0], result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
