{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srivamsikakarla/venkatasuryasatya_INFO5731_Fall2023/blob/main/srivamsiIn_class_exercise_05_04182023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5jPOZN6Vjsm"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 4/18/2023)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4b0vFm_Vjsp"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training.\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM\n",
        "\n",
        "(3) KNN\n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "(7) Word2Vec\n",
        "\n",
        "(8) BERT\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison\n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGYYBBdmVjsq",
        "outputId": "6c96bce2-deae-48de-f0ec-50a7290f32c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MultinomialNB...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 50%|█████     | 1/2 [00:03<00:03,  3.60s/it]C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Performance (MultinomialNB): {'Accuracy': 0.0, 'Recall': 0.0, 'Precision': 0.0, 'F1': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Validation Performance (MultinomialNB): {'Accuracy': 0.00028901734104046245, 'Recall': 0.0001446968600781363, 'Precision': 4.1819901756686797e-08, 'F1': 8.361563714425677e-08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Performance (MultinomialNB): {'Accuracy': 0.0, 'Recall': 0.0, 'Precision': 0.0, 'F1': 0.0}\n",
            "Training SVM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 50%|█████     | 1/2 [15:34<15:34, 934.37s/it]C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Felloh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 2/2 [31:32<00:00, 946.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Performance (SVM): {'Accuracy': 0.0, 'Recall': 0.0, 'Precision': 0.0, 'F1': 0.0}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Loading the dataset\n",
        "train_data = pd.read_csv(r'C:\\Users\\Felloh\\Downloads\\Compressed\\exercise05_datacollection.zip655920a929f6648552\\exercise09_datacollection\\stsa-train.txt', delimiter='\\t', header=None, names=['label', 'text'])\n",
        "test_data = pd.read_csv(r'C:\\Users\\Felloh\\Downloads\\Compressed\\exercise05_datacollection.zip655920a929f6648552\\exercise09_datacollection\\stsa-test.txt', delimiter='\\t', header=None, names=['label', 'text'])\n",
        "\n",
        "# Converting 'text' column to strings\n",
        "train_data['text'] = train_data['text'].astype(str)\n",
        "test_data['text'] = test_data['text'].astype(str)\n",
        "\n",
        "\n",
        "X = train_data['text'].values\n",
        "y = train_data['label'].values\n",
        "X_test = test_data['text'].values\n",
        "y_test = test_data['label'].values\n",
        "\n",
        "# Splitting the training data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Text preprocessing using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(X)\n",
        "X_test_counts = vectorizer.transform(X_test)\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "}\n",
        "\n",
        "#cross-validation\n",
        "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Training {clf_name}...\")\n",
        "    fold_results = []\n",
        "\n",
        "    for train_index, val_index in tqdm(kf.split(X_train_counts, y), total=kf.get_n_splits()):\n",
        "        X_train_fold, X_val_fold = X_train_counts[train_index], X_train_counts[val_index]\n",
        "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "        # Training the classifier on the current fold\n",
        "        clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "        # Predict on the validation set\n",
        "        y_pred = clf.predict(X_val_fold)\n",
        "\n",
        "        # Evaluating the model on the current fold\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "\n",
        "        # Use 'macro' average for multiclass precision, recall, and F1\n",
        "        precision = precision_score(y_val_fold, y_pred, average='macro')\n",
        "        recall = recall_score(y_val_fold, y_pred, average='macro')\n",
        "        f1 = f1_score(y_val_fold, y_pred, average='macro')\n",
        "\n",
        "        fold_results.append({\n",
        "            'Accuracy': accuracy,\n",
        "            'Recall': recall,\n",
        "            'Precision': precision,\n",
        "            'F1': f1\n",
        "        })\n",
        "\n",
        "    # Printing average performance over all folds\n",
        "    avg_results = {metric: np.mean([result[metric] for result in fold_results]) for metric in fold_results[0]}\n",
        "    print(f\"Avg. Performance ({clf_name}): {avg_results}\")\n",
        "\n",
        "    # Training the final model on the entire training set\n",
        "    clf.fit(X_train_counts, y)\n",
        "\n",
        "    # Evaluating the final model on the validation set\n",
        "    y_val_pred = clf.predict(X_train_counts)\n",
        "    final_results_val = {\n",
        "        'Accuracy': accuracy_score(y, y_val_pred),\n",
        "        'Recall': recall_score(y, y_val_pred, average='macro'),\n",
        "        'Precision': precision_score(y, y_val_pred, average='macro'),\n",
        "        'F1': f1_score(y, y_val_pred, average='macro'),\n",
        "    }\n",
        "    print(f\"Final Validation Performance ({clf_name}): {final_results_val}\")\n",
        "\n",
        "    # Evaluating the model on the test set\n",
        "    y_test_pred = clf.predict(X_test_counts)\n",
        "    final_results_test = {\n",
        "        'Accuracy': accuracy_score(y_test, y_test_pred),\n",
        "        'Recall': recall_score(y_test, y_test_pred, average='macro'),\n",
        "        'Precision': precision_score(y_test, y_test_pred, average='macro'),\n",
        "        'F1': f1_score(y_test, y_test_pred, average='macro'),\n",
        "    }\n",
        "    print(f\"Final Test Performance ({clf_name}): {final_results_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WXHD5KzVjsu"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K-means\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Hierarchical clustering\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6VoE9JaVjsu"
      },
      "outputs": [],
      "source": [
        "!pip install --user sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYow_Xg-Vjsv"
      },
      "outputs": [],
      "source": [
        "!pip install gensim scikit-learn matplotlib seaborn sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SfHHzLgVjsv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from gensim.models import Word2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Loading the dataset\n",
        "df = pd.read_csv(r'C:\\Users\\Felloh\\Downloads\\Compressed\\archive_8\\Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Dropping rows with NaN values in the 'Reviews' column\n",
        "df = df.dropna(subset=['Reviews'])\n",
        "\n",
        "# Extracting features using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Reviews'])\n",
        "\n",
        "# Function to perform clustering and visualize results\n",
        "def perform_clustering_and_visualization(model, name, X, true_labels=None):\n",
        "    # Fitting the model\n",
        "    labels = model.fit_predict(X)\n",
        "\n",
        "    # Visualizing the clusters in 2D using TruncatedSVD\n",
        "    svd = TruncatedSVD(n_components=2)\n",
        "    reduced_features = svd.fit_transform(X)\n",
        "    reduced_df = pd.DataFrame(reduced_features, columns=['Feature_1', 'Feature_2'])\n",
        "    reduced_df['Cluster'] = labels\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x='Feature_1', y='Feature_2', hue='Cluster', data=reduced_df, palette='viridis', legend='full')\n",
        "    plt.title(f'{name} Clustering')\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluating silhouette score (if true labels are available)\n",
        "    if true_labels is not None:\n",
        "        silhouette_avg = silhouette_score(X, labels)\n",
        "        print(f'Silhouette Score ({name}): {silhouette_avg:.4f}')\n",
        "\n",
        "# Applying K-means clustering\n",
        "kmeans_model = KMeans(n_clusters=5, random_state=42)\n",
        "perform_clustering_and_visualization(kmeans_model, 'K-means', tfidf_matrix)\n",
        "\n",
        "# Applying DBSCAN clustering\n",
        "dbscan_model = DBSCAN(eps=0.5, min_samples=5)\n",
        "perform_clustering_and_visualization(dbscan_model, 'DBSCAN', tfidf_matrix)\n",
        "\n",
        "# Applying Hierarchical clustering\n",
        "hierarchical_model = AgglomerativeClustering(n_clusters=5)\n",
        "perform_clustering_and_visualization(hierarchical_model, 'Hierarchical', tfidf_matrix)\n",
        "\n",
        "# Word2Vec clustering (using Gensim Word2Vec model)\n",
        "word2vec_model = Word2Vec(sentences=[text.split() for text in df['Reviews']], vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_matrix = pd.DataFrame([word2vec_model.wv[word] for word in word2vec_model.wv.index_to_key])\n",
        "perform_clustering_and_visualization(KMeans(n_clusters=5, random_state=42), 'Word2Vec', word2vec_matrix, None)\n",
        "\n",
        "# BERT clustering (using Sentence Transformers)\n",
        "bert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "bert_embeddings = bert_model.encode(df['Reviews'].tolist(), show_progress_bar=True)\n",
        "perform_clustering_and_visualization(KMeans(n_clusters=5, random_state=42), 'BERT', bert_embeddings, None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vucuTDKCVjsw"
      },
      "source": [
        "In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmTK5zhIVjsw"
      },
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "Thе rеsults of thе clustеring mеthods vary significantly in tеrms of thеir approachеs and outcomеs on thе givеn datasеt. K-mеans clustеring dеmonstratеd rеlativеly wеll-dеfinеd clustеrs in thе 2D PCA visualization, assigning data points to distinct groups. DBSCAN, on thе othеr hand, еxhibitеd a morе flеxiblе approach by idеntifying dеnsе rеgions, allowing for varying clustеr shapеs and sizеs. Hiеrarchical clustеring prеsеntеd a clеar hiеrarchy of clustеrs, showcasing thе rеlationship bеtwееn diffеrеnt lеvеls of data grouping. Word2Vеc, utilizing Gеnsim's Word2Vеc modеl, yiеldеd clustеrs basеd on sеmantic similaritiеs in thе word еmbеddings, providing insights into contеxtual rеlationships within thе tеxt. BERT еmbеddings, obtainеd from thе Sеntеncе Transformеrs library, dеmonstratеd a nuancеd undеrstanding of tеxtual sеmantics, capturing intricatе pattеrns in thе data. Thе choicе of clustеring mеthod should bе influеncеd by thе spеcific goals of thе analysis, as еach mеthod brings its own strеngths and limitations to thе task at hand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJmHLrOpVjsx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}